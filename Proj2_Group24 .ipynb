{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group number 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset which we're using for classification was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted having around 32000 rows and 15 columns.We have about 7 to 8 percent of incomplete data and categorical variables like Sex, Workclass, Race and few others. The prediction task is to determine whether a person makes over $50000 a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing few packages required\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "classification_data = pd.DataFrame(pd.read_csv('classification_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age          Workclass    fnlwgt    Education  Education-num  \\\n",
       "0       39          State-gov   77516.0    Bachelors           13.0   \n",
       "1       50   Self-emp-not-inc   83311.0    Bachelors           13.0   \n",
       "2       38            Private  215646.0      HS-grad            9.0   \n",
       "3       53            Private  234721.0         11th            7.0   \n",
       "4       28            Private  338409.0    Bachelors           13.0   \n",
       "...    ...                ...       ...          ...            ...   \n",
       "32556   27            Private  257302.0   Assoc-acdm           12.0   \n",
       "32557   40            Private  154374.0      HS-grad            9.0   \n",
       "32558   58            Private  151910.0      HS-grad            9.0   \n",
       "32559   22            Private  201490.0      HS-grad            9.0   \n",
       "32560   52       Self-emp-inc  287927.0      HS-grad            9.0   \n",
       "\n",
       "            Marital-status          Occupation    Relationship    Race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           Sex  Capital-gain  Capital-loss  hours-per-week  native-country  \\\n",
       "0         Male        2174.0           0.0            40.0   United-States   \n",
       "1         Male           0.0           0.0            13.0   United-States   \n",
       "2         Male           0.0           0.0            40.0   United-States   \n",
       "3         Male           0.0           0.0            40.0   United-States   \n",
       "4       Female           0.0           0.0            40.0            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female           0.0           0.0            38.0   United-States   \n",
       "32557     Male           0.0           0.0            40.0   United-States   \n",
       "32558   Female           0.0           0.0            40.0   United-States   \n",
       "32559     Male           0.0           0.0            20.0   United-States   \n",
       "32560   Female       15024.0           0.0            40.0   United-States   \n",
       "\n",
       "       Income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the data\n",
    "classification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " checking for missing data and apply data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             32561 non-null  int64  \n",
      " 1   Workclass       32561 non-null  object \n",
      " 2   fnlwgt          32444 non-null  float64\n",
      " 3   Education       32458 non-null  object \n",
      " 4   Education-num   32331 non-null  float64\n",
      " 5   Marital-status  32356 non-null  object \n",
      " 6   Occupation      32233 non-null  object \n",
      " 7   Relationship    32462 non-null  object \n",
      " 8   Race            32255 non-null  object \n",
      " 9   Sex             32338 non-null  object \n",
      " 10  Capital-gain    32306 non-null  float64\n",
      " 11  Capital-loss    32453 non-null  float64\n",
      " 12  hours-per-week  32451 non-null  float64\n",
      " 13  native-country  32437 non-null  object \n",
      " 14  Income          32561 non-null  object \n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "classification_data.info()\n",
    "# we have total of 32561 rows and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 0\n",
       "Workclass           0\n",
       "fnlwgt            117\n",
       "Education         103\n",
       "Education-num     230\n",
       "Marital-status    205\n",
       "Occupation        328\n",
       "Relationship       99\n",
       "Race              306\n",
       "Sex               223\n",
       "Capital-gain      255\n",
       "Capital-loss      108\n",
       "hours-per-week    110\n",
       "native-country    124\n",
       "Income              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data has null values in it\n",
    "classification_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Private             22696\n",
       " Self-emp-not-inc     2541\n",
       " Local-gov            2093\n",
       " ?                    1836\n",
       " State-gov            1298\n",
       " Self-emp-inc         1116\n",
       " Federal-gov           960\n",
       " Without-pay            14\n",
       " Never-worked            7\n",
       "Name: Workclass, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " HS-grad         10459\n",
       " Some-college     7271\n",
       " Bachelors        5339\n",
       " Masters          1715\n",
       " Assoc-voc        1380\n",
       " 11th             1173\n",
       " Assoc-acdm       1065\n",
       " 10th              931\n",
       " 7th-8th           643\n",
       " Prof-school       574\n",
       " 9th               512\n",
       " 12th              432\n",
       " Doctorate         412\n",
       " 5th-6th           333\n",
       " 1st-4th           168\n",
       " Preschool          51\n",
       "Name: Education, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Married-civ-spouse       14895\n",
       " Never-married            10601\n",
       " Divorced                  4418\n",
       " Separated                 1018\n",
       " Widowed                    987\n",
       " Married-spouse-absent      414\n",
       " Married-AF-spouse           23\n",
       "Name: Marital-status, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Prof-specialty       4100\n",
       " Craft-repair         4047\n",
       " Exec-managerial      4034\n",
       " Adm-clerical         3735\n",
       " Sales                3610\n",
       " Other-service        3261\n",
       " Machine-op-inspct    1978\n",
       " ?                    1828\n",
       " Transport-moving     1580\n",
       " Handlers-cleaners    1356\n",
       " Farming-fishing       985\n",
       " Tech-support          921\n",
       " Protective-serv       641\n",
       " Priv-house-serv       148\n",
       " Armed-Forces            9\n",
       "Name: Occupation, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Husband           13148\n",
       " Not-in-family      8282\n",
       " Own-child          5053\n",
       " Unmarried          3436\n",
       " Wife               1565\n",
       " Other-relative      978\n",
       "Name: Relationship, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " White                 27556\n",
       " Black                  3103\n",
       " Asian-Pac-Islander     1024\n",
       " Amer-Indian-Eskimo      305\n",
       " Other                   267\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Male      21644\n",
       " Female    10694\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " United-States                 29053\n",
       " Mexico                          641\n",
       " ?                               583\n",
       " Philippines                     198\n",
       " Germany                         136\n",
       " Canada                          121\n",
       " Puerto-Rico                     114\n",
       " El-Salvador                     106\n",
       " India                           100\n",
       " Cuba                             95\n",
       " England                          90\n",
       " Jamaica                          81\n",
       " South                            80\n",
       " China                            74\n",
       " Italy                            73\n",
       " Dominican-Republic               70\n",
       " Vietnam                          66\n",
       " Japan                            62\n",
       " Guatemala                        62\n",
       " Poland                           60\n",
       " Columbia                         59\n",
       " Taiwan                           51\n",
       " Haiti                            44\n",
       " Iran                             43\n",
       " Portugal                         37\n",
       " Nicaragua                        34\n",
       " Peru                             31\n",
       " Greece                           29\n",
       " France                           29\n",
       " Ecuador                          28\n",
       " Ireland                          24\n",
       " Hong                             20\n",
       " Cambodia                         19\n",
       " Trinadad&Tobago                  19\n",
       " Thailand                         18\n",
       " Laos                             18\n",
       " Yugoslavia                       16\n",
       " Outlying-US(Guam-USVI-etc)       14\n",
       " Hungary                          13\n",
       " Honduras                         13\n",
       " Scotland                         12\n",
       " Holand-Netherlands                1\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the mean of the cloumn values in the null positions(for numeric values)\n",
    "#fnlwgt is final weight which is very important variabale in our adult census dataset and it's positively corelated to the below 3 columns Race,age and sex.\n",
    "#So we did group by to those 3 columns.\n",
    "classification_data['fnlwgt'] = classification_data['fnlwgt'].fillna(classification_data.groupby(['Race','Age','Sex'])['fnlwgt'].transform('mean'))\n",
    "#Capital-gain and capital loss are positively corelated to workclass and age. \n",
    "classification_data['Capital-gain'] = classification_data['Capital-gain'].fillna(classification_data.groupby(['Workclass'])['Capital-gain'].transform('mean'))\n",
    "classification_data['Capital-loss'] = classification_data['Capital-loss'].fillna(classification_data.groupby(['Workclass','Age'])['Capital-loss'].transform('mean'))\n",
    "#Education-num is strongly positively corelated to Education number \n",
    "classification_data['Education-num'] = classification_data['Education-num'].fillna(classification_data.groupby('Education')['Education-num'].transform('mean'))\n",
    "#number of working hours in a week is dependent on the work class and the age(experience) of an employee.\n",
    "classification_data['hours-per-week'] = classification_data['hours-per-week'].fillna(classification_data.groupby(['Workclass','Age'])['hours-per-week'].transform('mean'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the mode of the column in the incomplete data of the catagorical variables\n",
    "classification_data['Education'].fillna('HS-grad', inplace=True)\n",
    "classification_data['Marital-status'].fillna('Married-civ-spouse', inplace=True)\n",
    "classification_data['Occupation'].fillna('Prof-specialty', inplace=True)\n",
    "classification_data['Relationship'].fillna('Husband', inplace=True)\n",
    "classification_data['Race'].fillna('White', inplace=True)\n",
    "classification_data['Sex'].fillna('Male', inplace=True)\n",
    "classification_data['native-country'].fillna('United-States', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Workclass         0\n",
       "fnlwgt            0\n",
       "Education         0\n",
       "Education-num     0\n",
       "Marital-status    0\n",
       "Occupation        0\n",
       "Relationship      0\n",
       "Race              0\n",
       "Sex               0\n",
       "Capital-gain      0\n",
       "Capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "Income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can see that there are no null values\n",
    "classification_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Marital-status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age          Workclass    fnlwgt    Education  Education-num  \\\n",
       "0       39          State-gov   77516.0    Bachelors           13.0   \n",
       "1       50   Self-emp-not-inc   83311.0    Bachelors           13.0   \n",
       "2       38            Private  215646.0      HS-grad            9.0   \n",
       "3       53            Private  234721.0         11th            7.0   \n",
       "4       28            Private  338409.0    Bachelors           13.0   \n",
       "...    ...                ...       ...          ...            ...   \n",
       "32556   27            Private  257302.0   Assoc-acdm           12.0   \n",
       "32557   40            Private  154374.0      HS-grad            9.0   \n",
       "32558   58            Private  151910.0      HS-grad            9.0   \n",
       "32559   22            Private  201490.0      HS-grad            9.0   \n",
       "32560   52       Self-emp-inc  287927.0      HS-grad            9.0   \n",
       "\n",
       "            Marital-status          Occupation    Relationship    Race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           Sex  Capital-gain  Capital-loss  hours-per-week  native-country  \\\n",
       "0         Male        2174.0           0.0            40.0   United-States   \n",
       "1         Male           0.0           0.0            13.0   United-States   \n",
       "2         Male           0.0           0.0            40.0   United-States   \n",
       "3         Male           0.0           0.0            40.0   United-States   \n",
       "4       Female           0.0           0.0            40.0            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female           0.0           0.0            38.0   United-States   \n",
       "32557     Male           0.0           0.0            40.0   United-States   \n",
       "32558   Female           0.0           0.0            40.0   United-States   \n",
       "32559     Male           0.0           0.0            20.0   United-States   \n",
       "32560   Female       15024.0           0.0            40.0   United-States   \n",
       "\n",
       "       Income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies\n",
    "dummies = pd.get_dummies(classification_data.Workclass, prefix = 'Workclass')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "dummies = pd.get_dummies(classification_data.Education, prefix = 'Education')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "dummies = pd.get_dummies(classification_data['Marital-status'], prefix = 'Marital-status')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "dummies = pd.get_dummies(classification_data.Occupation, prefix = 'Occupation')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "dummies = pd.get_dummies(classification_data.Relationship, prefix = 'Relationship')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "dummies = pd.get_dummies(classification_data.Race, prefix = 'Race')\n",
    "classification_data = pd.concat([classification_data,dummies],axis = 'columns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up boolean values for the sex as it has only two values(male,Female)\n",
    "le =LabelEncoder()\n",
    "classification_data['Sex'] = le.fit_transform(classification_data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns which comparatively are not much useful in predicting\n",
    "classification_data.drop(columns=['Workclass', 'Education', 'Marital-status', 'Occupation','Relationship','native-country','Race'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education-num</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital-gain</th>\n",
       "      <th>Capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>Income</th>\n",
       "      <th>Workclass_ ?</th>\n",
       "      <th>Workclass_ Federal-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>Relationship_ Own-child</th>\n",
       "      <th>Relationship_ Unmarried</th>\n",
       "      <th>Relationship_ Wife</th>\n",
       "      <th>Relationship_Husband</th>\n",
       "      <th>Race_ Amer-Indian-Eskimo</th>\n",
       "      <th>Race_ Asian-Pac-Islander</th>\n",
       "      <th>Race_ Black</th>\n",
       "      <th>Race_ Other</th>\n",
       "      <th>Race_ White</th>\n",
       "      <th>Race_White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age    fnlwgt  Education-num  Sex  Capital-gain  Capital-loss  \\\n",
       "0       39   77516.0           13.0    1        2174.0           0.0   \n",
       "1       50   83311.0           13.0    1           0.0           0.0   \n",
       "2       38  215646.0            9.0    1           0.0           0.0   \n",
       "3       53  234721.0            7.0    1           0.0           0.0   \n",
       "4       28  338409.0           13.0    0           0.0           0.0   \n",
       "...    ...       ...            ...  ...           ...           ...   \n",
       "32556   27  257302.0           12.0    0           0.0           0.0   \n",
       "32557   40  154374.0            9.0    1           0.0           0.0   \n",
       "32558   58  151910.0            9.0    0           0.0           0.0   \n",
       "32559   22  201490.0            9.0    1           0.0           0.0   \n",
       "32560   52  287927.0            9.0    0       15024.0           0.0   \n",
       "\n",
       "       hours-per-week  Income  Workclass_ ?  Workclass_ Federal-gov  ...  \\\n",
       "0                40.0   <=50K             0                       0  ...   \n",
       "1                13.0   <=50K             0                       0  ...   \n",
       "2                40.0   <=50K             0                       0  ...   \n",
       "3                40.0   <=50K             0                       0  ...   \n",
       "4                40.0   <=50K             0                       0  ...   \n",
       "...               ...     ...           ...                     ...  ...   \n",
       "32556            38.0   <=50K             0                       0  ...   \n",
       "32557            40.0    >50K             0                       0  ...   \n",
       "32558            40.0   <=50K             0                       0  ...   \n",
       "32559            20.0   <=50K             0                       0  ...   \n",
       "32560            40.0    >50K             0                       0  ...   \n",
       "\n",
       "       Relationship_ Own-child  Relationship_ Unmarried  Relationship_ Wife  \\\n",
       "0                            0                        0                   0   \n",
       "1                            0                        0                   0   \n",
       "2                            0                        0                   0   \n",
       "3                            0                        0                   0   \n",
       "4                            0                        0                   1   \n",
       "...                        ...                      ...                 ...   \n",
       "32556                        0                        0                   1   \n",
       "32557                        0                        0                   0   \n",
       "32558                        0                        1                   0   \n",
       "32559                        1                        0                   0   \n",
       "32560                        0                        0                   1   \n",
       "\n",
       "       Relationship_Husband  Race_ Amer-Indian-Eskimo  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "...                     ...                       ...   \n",
       "32556                     0                         0   \n",
       "32557                     0                         0   \n",
       "32558                     0                         0   \n",
       "32559                     0                         0   \n",
       "32560                     0                         0   \n",
       "\n",
       "       Race_ Asian-Pac-Islander  Race_ Black  Race_ Other  Race_ White  \\\n",
       "0                             0            0            0            1   \n",
       "1                             0            0            0            1   \n",
       "2                             0            0            0            1   \n",
       "3                             0            1            0            0   \n",
       "4                             0            1            0            0   \n",
       "...                         ...          ...          ...          ...   \n",
       "32556                         0            0            0            1   \n",
       "32557                         0            0            0            1   \n",
       "32558                         0            0            0            1   \n",
       "32559                         0            0            0            1   \n",
       "32560                         0            0            0            1   \n",
       "\n",
       "       Race_White  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "32556           0  \n",
       "32557           0  \n",
       "32558           0  \n",
       "32559           0  \n",
       "32560           0  \n",
       "\n",
       "[32561 rows x 71 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Data and standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classification_data.drop(columns = 'Income')\n",
    "y = classification_data['Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data and standardizing the values\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X,y,test_size=.25,random_state=0)\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "X_train = stdscaler.fit_transform(X_train_org)\n",
    "X_test = stdscaler.transform(X_test_org)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard voting classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "log_clf = LogisticRegression(C = 100)\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(20)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8500184252548827\n",
      "KNeighborsClassifier 0.8301191499815748\n",
      "VotingClassifier 0.8435081685296647\n"
     ]
    }
   ],
   "source": [
    "# soft voting classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "log_clf = LogisticRegression(C = 100)\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(20)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Among the above two voting classifiers, soft voting classifier gives more accurate predictions as the accuracy score is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8307\n",
      "Train score: 0.8362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=2)\n",
    "bag1_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag1_clf.fit(X_train, y_train)\n",
    "y_pred = bag1_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(bag1_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8122\n",
      "Train score: 0.8145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(10)\n",
    "bag2_clf = BaggingClassifier(knn_clf, n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag2_clf.fit(X_train, y_train)\n",
    "y_pred = bag2_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(bag2_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8311\n",
      "Train score: 0.8358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=2)\n",
    "past1_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "past1_clf.fit(X_train, y_train)\n",
    "y_pred = past1_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(past1_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8118\n",
      "Train score: 0.8145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(10)\n",
    "past2_clf = BaggingClassifier(knn_clf, n_estimators=500, max_samples=100, bootstrap=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "past2_clf.fit(X_train, y_train)\n",
    "y_pred = past2_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(past2_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8680\n",
      "Train score: 0.8833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada1_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), learning_rate = 0.5,n_estimators=200, random_state=0)\n",
    "ada1_clf.fit(X_train, y_train)\n",
    "y_pred = ada1_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(ada1_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8488\n",
      "Train score: 0.8504\n"
     ]
    }
   ],
   "source": [
    "ada2_clf = AdaBoostClassifier(LogisticRegression(C = 100), n_estimators=200,learning_rate=1, random_state=0)\n",
    "ada2_clf.fit(X_train, y_train)\n",
    "ada2_clf.fit(X_train, y_train)\n",
    "y_pred = ada2_clf.predict(X_test)\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(ada2_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8479\n",
      "Train score: 0.8505\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "gb_clf = GradientBoostingClassifier(max_depth=3, n_estimators=20, learning_rate=0.1, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_pred)))\n",
    "print('Train score: {:.4f}'.format(gb_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA-Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10)\n",
    "X1 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12297266e+05,  1.10073681e+03, -8.99781329e+01,\n",
       "        -8.21969031e-01, -3.95437768e-01, -2.90225204e+00,\n",
       "         7.86405421e-01,  3.36572238e-01,  3.66315941e-01,\n",
       "        -8.52781658e-01],\n",
       "       [-1.06502320e+05, -1.07340491e+03, -9.35184705e+01,\n",
       "         3.02843166e+00, -2.91327773e+01, -3.76928256e+00,\n",
       "        -1.26605507e+00,  3.09986338e-01,  4.00626373e-01,\n",
       "        -2.60435673e-01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=pd.DataFrame(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_org, X2_test_org, y_train, y_test = train_test_split(X2,y,test_size=.25,random_state=0)\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "X2_train = stdscaler.fit_transform(X2_train_org)\n",
    "X2_test = stdscaler.transform(X2_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for the model :  0.009129040217123118\n",
      "Best estimator for the model :  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
      "                     weights='distance')\n",
      "Best parameters for the model :  {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_parameters = {'n_neighbors' : [3, 5, 11, 15], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "gridsearch = GridSearchCV(KNeighborsClassifier(), grid_parameters, verbose = 1, cv = 3, n_jobs = -1)\n",
    "gridsearch_fit = gridsearch.fit(X2_train, y_train)\n",
    "print(\"Best score for the model : \", gridsearch_fit.best_score_)\n",
    "print(\"Best estimator for the model : \",gridsearch_fit.best_estimator_)\n",
    "print(\"Best parameters for the model : \",gridsearch_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This KNeighborsClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-e379774a97b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreport_table\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreport_table1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'knn_clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k = 15'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgridsearch_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport_table1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Model name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Model parameter'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Train accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Test accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Best Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \"\"\"\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This KNeighborsClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "report_table=0\n",
    "report_table1 = [['knn_clf', 'k = 15', knn_clf.score(X2_train, y_train), knn_clf.score(X2_test, y_test), gridsearch_fit.best_score_ ]]\n",
    "report = pd.DataFrame(report_table1,columns = ['Model name', 'Model parameter', 'Train accuracy', 'Test accuracy','Best Score'])\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :  0.8402538902538902\n",
      "Best estimator:  LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Best parameters:  {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X2_train, y_train)\n",
    "grid_parameters = {'penalty': ['l1','l2'], 'C': [0.1,1,10,100,1000]} \n",
    "logistic_fit = GridSearchCV(logistic, grid_parameters, cv = 3)\n",
    "gridsearchcv_fit = logistic_fit.fit(X2_train, y_train)\n",
    "print(\"Best score : \", gridsearchcv_fit.best_score_)\n",
    "print(\"Best estimator: \",gridsearchcv_fit.best_estimator_)\n",
    "print(\"Best parameters: \",gridsearchcv_fit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :  0.8409909909909911\n",
      "Best estimator:  LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "Best parameters:  {'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linearsvm = LinearSVC()\n",
    "param_values = {'C': [0.1,10,1000]} \n",
    "linearsvm_gridsearch = GridSearchCV(linearsvm, param_values, cv = 3)\n",
    "linearsvm_gridsearch_fit = linearsvm_gridsearch.fit(X2_train, y_train)\n",
    "print(\"Best score : \", linearsvm_gridsearch_fit.best_score_)\n",
    "print(\"Best estimator: \",linearsvm_gridsearch_fit.best_estimator_)\n",
    "print(\"Best parameters: \",linearsvm_gridsearch_fit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized Support Vector Machine (rbf, poly, and linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :  0.8504504504504503\n",
      "Best estimator:  SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Best parameters:  {'C': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "kernelsvc = SVC()\n",
    "parameters = {'kernel': ['rbf','linear','poly'], 'C' : [0.1, 1]}             \n",
    "kernel_svm = GridSearchCV(kernelsvc, parameters, cv = 3)\n",
    "kernel_svmfit = kernel_svm.fit(X2_train, y_train)\n",
    "print(\"Best score : \", kernel_svmfit.best_score_)\n",
    "print(\"Best estimator: \",kernel_svmfit.best_estimator_)\n",
    "print(\"Best parameters: \",kernel_svmfit.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :  0.8495904995904996\n",
      "Best estimator:  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Best parameters:  {'criterion': 'gini', 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "decisiontree = tree.DecisionTreeClassifier()\n",
    "decisiontree.fit(X2_train, y_train)\n",
    "param = {'criterion':['gini','entropy'], 'max_depth': range(2,20)}\n",
    "decisiontree_gs = GridSearchCV(tree.DecisionTreeClassifier(), param, cv = 2)\n",
    "decisiontree_gs_fit = decisiontree_gs.fit(X2_train, y_train)\n",
    "print(\"Best score : \", decisiontree_gs_fit.best_score_)\n",
    "print(\"Best estimator: \",decisiontree_gs_fit.best_estimator_)\n",
    "print(\"Best parameters: \",decisiontree_gs_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-72-a55e52fefcf0>\", line 5, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-72-a55e52fefcf0>\", line 5, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-72-a55e52fefcf0>\", line 5, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: can only concatenate str (not \"list\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-72-a55e52fefcf0>\", line 5, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 6, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 29, in <module>\n",
      "    from tensorflow.core.protobuf import config_pb2\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3348, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1418, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1318, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: can only concatenate str (not \"list\") to str\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 242, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\ANISHA\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: The specified module could not be found.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3347\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3350\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1418\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1318\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1319\u001b[0m             )\n\u001b[0;32m   1320\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # create model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Fit the model\n",
    "# model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# # evaluate the model\n",
    "# scores = model.evaluate(X_test, y_test)\n",
    "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# y_predict = model.predict(X_test)\n",
    "# y_predict\n",
    "# print('accuracy : {:.4f}' .format(accuracy_score(y_test, y_predict)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
